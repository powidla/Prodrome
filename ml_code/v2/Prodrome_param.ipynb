{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFMzIQuXlvm8",
        "outputId": "e37d9c87-64ff-4b19-cd4e-3dedd2abfb17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-7ab852ae96dd>:34: DtypeWarning: Columns (11,14,20,23,31,33,41,46,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv('df_data (1).csv', sep=\";\")\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "import random\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from lightgbm import LGBMClassifier\n",
        "# import shap\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import tqdm\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import copy\n",
        "\n",
        "data = pd.read_csv('df_data (1).csv', sep=\";\")\n",
        "data[\"ГБ новая\"] = data[\"ГБ новая\"].replace({'да': 1, 'нет': 0})\n",
        "data_not_import = data[[\"startAnswering\", \"id\", \"комментарий\"]]\n",
        "data = data.drop(columns=[\"startAnswering\", \"id\", \"комментарий\"], axis=1)\n",
        "categorical_columns = [\n",
        "                       \"сыр, шоко, цитрус\", \"Физическая ативность\", ]\n",
        "binary_columns = ['Жажда', 'кофеин', 'Зевания', 'ГБ новая', 'Алкоголь'\n",
        "                  , \"боль в шее\", \"вегетатика\", \"подташнивает\",\n",
        "                   \"мочеиспускание\", \"Напряжение глаз\", \"Воды достаточно?\", \"Были резкие запахи?\",\n",
        "                    \"Пропуск приема пищи\", \"Чувствит кожи головы\",\n",
        "                   \"Хотелось шоколада\"]\n",
        "quantitative_columns = [\"Тревога\", \"Депрессия\", \"Сонливость\", \"Чувство голода\",\n",
        "                        \"Работосособность\", \"Чувство усталости\", \"Раздражительность\"\n",
        "\n",
        "                        ]\n",
        "time_data =['time']\n",
        "date_data = [\"date\"]\n",
        "time_data =['time']\n",
        "date_data = [\"date\"]\n",
        "longest_string_index = data[['time', \"Начало боли\", \"Продолжительность сна\", \"Окончание боли\"]].apply(lambda x: ''.join(x.astype(str)), axis=1).str.len().idxmax()\n",
        "longest_string = data.loc[longest_string_index, ['time', \"Начало боли\", \"Продолжительность сна\", \"Окончание боли\"]]\n",
        "data = data.drop(columns=[\"Боль сейчас\"], axis=1)\n",
        "data = data.drop(data.iloc[:, 27:58],axis = 1)\n",
        "data = data.drop(columns=[\"Ожидаете мигрень\"], axis=1)\n",
        "mode_values = data.mode().iloc[0]\n",
        "\n",
        "# Fill NaN values with mode values in all columns\n",
        "data = data.fillna(mode_values)\n",
        "data[\"ГБ новая\"] = data[\"ГБ новая\"].astype(int)\n",
        "target = data[\"ГБ новая\"]\n",
        "y = data[\"ГБ новая\"].values\n",
        "data = data.drop(columns = [\"ГБ новая\"], axis=1)\n",
        "binary_columns = ['Жажда', 'кофеин', 'Зевания',  'Алкоголь'\n",
        "                  , \"боль в шее\", \"вегетатика\", \"подташнивает\",\n",
        "                   \"мочеиспускание\", \"Напряжение глаз\", \"Воды достаточно?\", \"Были резкие запахи?\",\n",
        "                    \"Пропуск приема пищи\", \"Чувствит кожи головы\",\n",
        "                   \"Хотелось шоколада\"]\n",
        "\n",
        "for column in binary_columns:\n",
        "    data[column] = data[column].replace({'да': 1, 'нет': 0})\n",
        "\n",
        "for column in time_data:\n",
        "    data[column] = pd.to_datetime(data[column], format='%H:%M')\n",
        "\n",
        "for column in time_data:\n",
        "    time_components = [f'{column}_hour', f'{column}_minute']\n",
        "\n",
        "    data[time_components] = data[column].apply(lambda x: pd.Series([x.hour, x.minute]))\n",
        "    data_encoded = pd.get_dummies(data, columns=time_components)\n",
        "\n",
        "\n",
        "data = pd.get_dummies(data, columns=categorical_columns+quantitative_columns+binary_columns)\n",
        "\n",
        "data[\"time\"] = pd.to_datetime(data[\"time\"]).dt.time\n",
        "data[\"datetime\"] = pd.to_datetime(data[\"date\"] + \" \" + data[\"time\"].astype(str))\n",
        "\n",
        "# Set the datetime column as the index\n",
        "# data.set_index(\"datetime\", inplace=True)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "data.drop([\"date\", \"time\", \"datetime\"], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:, 2:].values"
      ],
      "metadata": {
        "id": "mr03Pe24l8vE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, shuffle=True)"
      ],
      "metadata": {
        "id": "uXQsnUI-mA0P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 Run for params"
      ],
      "metadata": {
        "id": "13Tkx0RzmYkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "cOy5_ZY0mn8g"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Define the hyperparameters for each model\n",
        "params_lr = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty': ['l1', 'l2']}\n",
        "params_rf = {'n_estimators': [100, 200, 300, 400, 500], 'max_depth': [5, 10, 15, 20, None]}\n",
        "params_svm = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
        "params_gb = {'n_estimators': [100, 200, 300], 'learning_rate': [0.1, 0.05, 0.01], 'max_depth': [3, 4, 5]}\n",
        "params_knn = {'n_neighbors': list(range(1, 31)), 'weights': ['uniform', 'distance']}\n",
        "params_lgbm = {'n_estimators': [100, 200, 300], 'learning_rate': [0.1, 0.05, 0.01], 'max_depth': [3, 4, 5]}\n",
        "\n",
        "# Define models\n",
        "models = [\n",
        "    ('LR', LogisticRegression(), params_lr),\n",
        "    ('RF', RandomForestClassifier(), params_rf),\n",
        "    ('SVM', SVC(probability=True), params_svm),\n",
        "    ('GB', GradientBoostingClassifier(), params_gb),\n",
        "    ('KNN', KNeighborsClassifier(), params_knn),\n",
        "    ('LGBM', LGBMClassifier(), params_lgbm)\n",
        "]\n",
        "\n",
        "for name, model, params in models:\n",
        "    gs = GridSearchCV(model, params, cv=5, scoring='roc_auc', n_jobs=-1)\n",
        "    gs.fit(X_train, y_train)\n",
        "    print(f\"Best parameters for {name}: {gs.best_params_}\")\n",
        "    print(f\"Best score for {name}: {gs.best_score_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHK2hhUDmZ7M",
        "outputId": "62235bbd-c26d-468d-8447-413d1b5416fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "35 fits failed out of a total of 70.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "35 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.72337929        nan 0.72723522        nan 0.72529946\n",
            "        nan 0.72439449        nan 0.72391483        nan 0.72385986\n",
            "        nan 0.72372289]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for LR: {'C': 0.01, 'penalty': 'l2'}\n",
            "Best score for LR: 0.7272352204039667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for RF: {'max_depth': 10, 'n_estimators': 400}\n",
            "Best score for RF: 0.732485074109838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 run for params"
      ],
      "metadata": {
        "id": "yyF_kHKcnXoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# More extensive hyperparameters for each model\n",
        "params_lr = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "             'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "             'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
        "\n",
        "params_rf = {'n_estimators': [100, 200, 300, 400, 500],\n",
        "             'max_depth': [5, 10, 15, 20, None],\n",
        "             'min_samples_split': [2, 5, 10],\n",
        "             'min_samples_leaf': [1, 2, 4],\n",
        "             'bootstrap': [True, False]}\n",
        "\n",
        "params_svm = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "              'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
        "              'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
        "\n",
        "params_gb = {'n_estimators': [100, 200, 300, 400, 500],\n",
        "             'learning_rate': [0.1, 0.05, 0.01, 0.005, 0.001],\n",
        "             'max_depth': [3, 4, 5, 6, 7, 8],\n",
        "             'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "             'min_samples_split': [2, 5, 10]}\n",
        "\n",
        "params_knn = {'n_neighbors': list(range(1, 31)),\n",
        "              'weights': ['uniform', 'distance'],\n",
        "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "              'p': [1, 2]}\n",
        "\n",
        "params_lgbm = {'n_estimators': [100, 200, 300, 400, 500],\n",
        "               'learning_rate': [0.1, 0.05, 0.01, 0.005, 0.001],\n",
        "               'max_depth': [-1, 3, 4, 5, 6, 7, 8],\n",
        "               'num_leaves': [7, 14, 31, 62, 125, 250, 500, 1000],\n",
        "               'min_child_samples': [5, 10, 20, 30]}\n",
        "\n",
        "# Define models\n",
        "models = [\n",
        "    ('LR', LogisticRegression(max_iter=5000), params_lr),\n",
        "    ('RF', RandomForestClassifier(), params_rf),\n",
        "    ('SVM', SVC(probability=True), params_svm),\n",
        "    ('GB', GradientBoostingClassifier(), params_gb),\n",
        "    ('KNN', KNeighborsClassifier(), params_knn),\n",
        "    ('LGBM', LGBMClassifier(), params_lgbm)\n",
        "]\n",
        "\n",
        "for name, model, params in models:\n",
        "    gs = GridSearchCV(model, params, cv=5, scoring='roc_auc', n_jobs=-1, verbose=2)\n",
        "    gs.fit(X_train, y_train)\n",
        "    print(f\"Best parameters for {name}: {gs.best_params_}\")\n",
        "    print(f\"Best score for {name}: {gs.best_score_}\")\n"
      ],
      "metadata": {
        "id": "F_QHoCSrnZsu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}